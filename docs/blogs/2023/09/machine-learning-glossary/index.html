<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Machine Learning Glossary | thomjiji</title>
<meta name="keywords" content="Machine Learning">
<meta name="description" content="Reference Machine Learning Glossary - Google for Developers
activation function A function that enables neural networks to learn non-linear (complex) relationships between features and the label. Popupar activation functions include:
ReLU Sigmoid Tanh backpropagation The algorithm that implements gradient descent in neural networks.
Training a neural network involves many iterations of the following two-pass cycle:
During the forward pass, the system processes a batch of examples to yild prediction(s). The system compares each prediction to each label value.">
<meta name="author" content="">
<link rel="canonical" href="https://thomjiji.github.io/blogs/2023/09/machine-learning-glossary/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.35ee184ca6eac1b199b1af4308e0b8e74ea71d6249a02c5252bbd9c9b7f5bf67.css" integrity="sha256-Ne4YTKbqwbGZsa9DCOC4506nHWJJoCxSUrvZybf1v2c=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://thomjiji.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://thomjiji.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://thomjiji.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://thomjiji.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://thomjiji.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><!DOCTYPE html>
<html lang="en">
  <head>
    <link rel="icon" href="https://thomjiji.github.io/powerpuff_girls_buttercup.jpg" />
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=IBM+Plex+Sans:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&family=JetBrains+Mono:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800&family=Space+Grotesk:wght@300;400;500;600;700&family=Roboto+Mono:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&display=swap"
      rel="stylesheet"
    />
  </head>

  <body>
    
  </body>
</html>
<meta property="og:title" content="Machine Learning Glossary" />
<meta property="og:description" content="Reference Machine Learning Glossary - Google for Developers
activation function A function that enables neural networks to learn non-linear (complex) relationships between features and the label. Popupar activation functions include:
ReLU Sigmoid Tanh backpropagation The algorithm that implements gradient descent in neural networks.
Training a neural network involves many iterations of the following two-pass cycle:
During the forward pass, the system processes a batch of examples to yild prediction(s). The system compares each prediction to each label value." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://thomjiji.github.io/blogs/2023/09/machine-learning-glossary/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-09-07T00:00:00+00:00" />
<meta property="article:modified_time" content="2023-09-07T00:00:00+00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Machine Learning Glossary"/>
<meta name="twitter:description" content="Reference Machine Learning Glossary - Google for Developers
activation function A function that enables neural networks to learn non-linear (complex) relationships between features and the label. Popupar activation functions include:
ReLU Sigmoid Tanh backpropagation The algorithm that implements gradient descent in neural networks.
Training a neural network involves many iterations of the following two-pass cycle:
During the forward pass, the system processes a batch of examples to yild prediction(s). The system compares each prediction to each label value."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://thomjiji.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Machine Learning Glossary",
      "item": "https://thomjiji.github.io/blogs/2023/09/machine-learning-glossary/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Machine Learning Glossary",
  "name": "Machine Learning Glossary",
  "description": "Reference Machine Learning Glossary - Google for Developers\nactivation function A function that enables neural networks to learn non-linear (complex) relationships between features and the label. Popupar activation functions include:\nReLU Sigmoid Tanh backpropagation The algorithm that implements gradient descent in neural networks.\nTraining a neural network involves many iterations of the following two-pass cycle:\nDuring the forward pass, the system processes a batch of examples to yild prediction(s). The system compares each prediction to each label value.",
  "keywords": [
    "Machine Learning"
  ],
  "articleBody": "Reference Machine Learning Glossary - Google for Developers\nactivation function A function that enables neural networks to learn non-linear (complex) relationships between features and the label. Popupar activation functions include:\nReLU Sigmoid Tanh backpropagation The algorithm that implements gradient descent in neural networks.\nTraining a neural network involves many iterations of the following two-pass cycle:\nDuring the forward pass, the system processes a batch of examples to yild prediction(s). The system compares each prediction to each label value. The difference between the prediction and the lable value is the loss for that example. The system aggregates the losses for all the examples to compute the total loss for the current batch. During the backward pass (backpropagation), the system reduces loss by adjusting the weights of all the neurons in all the hidden layer(s). Neural networks often contain many neurons across many hidden layers. Each of those neurons contribute to the overall loss in difference ways. Backpropagation determines whether to increase or decrease the weights applied to particular neurons.\nThe learning rate is a multiplier that controls the degree the which each backward pass increase or decreases each weight. A larget learning rate will increase or decrease each weight more than a small learning rate.\nIn calculus terms, backpropagation inplements calculus’ chain rule. That is, backpropagation calculuates the partial derivative of the error with respect to each parameter.\nmodel In general, any mathematical construct that processes input and returns output. Phrased differently, a model is the set of parameters and structure needed for a system to make predictions. In supervised machine learning, a model takes an example as input and infers a prediction as output. Within supervised machine learning, models differ somewhat. For example:\nA linear regression model consists of a set of weights and a bias. A neural network model consists of: A set of hidden layers, each containing one or more neurons. The weights and bias associated with each neuron. A decision tree model consists of: The shape of the tree; that is, the pattern in which the conditions and leaves are connected. The conditions and leaves. You can save, restore, or make copies of a model.\nUnsupervised machine learning also generates models, typically a function that can map an input example to the most appropriate cluster.\nembeddings An embedding is a relatively low-dimensional space into which you can translate high-dimensional vectors. Embeddings make it easier to do machine learning on large inputs like sparse vectors representing words. Ideally, an embedding captures some of the semantics of the input by placing semantically similar inputs close together in the embedding space. An embedding can be learned and reused across models.\nAutomatic Differentiation All modern deep learning frameworks take the differentiation work off of our plates by offering automatic differentiation (often shortened to autograd). As we pass data through each successive function, the framework build a computational graph that tracks how each value depends on others. To calculate derivatives, automatic differentiation works backwards through this graph applying the chain rule. The computational algorithm for applying the chain rule in this fashion is called backpropagation.\n",
  "wordCount" : "513",
  "inLanguage": "en",
  "datePublished": "2023-09-07T00:00:00Z",
  "dateModified": "2023-09-07T00:00:00Z",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://thomjiji.github.io/blogs/2023/09/machine-learning-glossary/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "thomjiji",
    "logo": {
      "@type": "ImageObject",
      "url": "https://thomjiji.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://thomjiji.github.io/" accesskey="h" title="thomjiji (Alt + H)">thomjiji</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://thomjiji.github.io/about/" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="https://thomjiji.github.io/archives/" title="Archives">
                    <span>Archives</span>
                </a>
            </li>
            <li>
                <a href="https://thomjiji.github.io/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://thomjiji.github.io/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://thomjiji.github.io/">Home</a>&nbsp;»&nbsp;<a href="https://thomjiji.github.io/posts/">Posts</a></div>
    <h1 class="post-title entry-hint-parent">
      Machine Learning Glossary
    </h1>
    <div class="post-meta"><span title='2023-09-07 00:00:00 +0000 UTC'>2023-09-07</span>

</div>
  </header> 
  <div class="post-content"><h2 id="reference">Reference<a hidden class="anchor" aria-hidden="true" href="#reference">#</a></h2>
<p><a href="https://developers.google.com/machine-learning/glossary" target="_blank" >Machine Learning Glossary - Google for
Developers</a></p>
<h2 id="activation-function">activation function<a hidden class="anchor" aria-hidden="true" href="#activation-function">#</a></h2>
<p>A function that enables neural networks to learn non-linear (complex) relationships
between features and the label. Popupar activation functions include:</p>
<ul>
<li>ReLU</li>
<li>Sigmoid</li>
<li>Tanh</li>
</ul>
<h2 id="backpropagation">backpropagation<a hidden class="anchor" aria-hidden="true" href="#backpropagation">#</a></h2>
<p>The algorithm that implements gradient descent in neural networks.</p>
<p>Training a neural network involves many iterations of the following two-pass cycle:</p>
<ol>
<li>During the <strong>forward pass</strong>, the system processes a batch of examples to yild
prediction(s). The system compares each prediction to each label value. The
difference between the prediction and the lable value is the loss for that example.
The system aggregates the losses for all the examples to compute the total loss for
the current batch.</li>
<li>During the <strong>backward pass</strong> (backpropagation), the system reduces loss by adjusting
the weights of all the neurons in all the hidden layer(s).</li>
</ol>
<p>Neural networks often contain many neurons across many hidden layers. Each of those
neurons contribute to the overall loss in difference ways. Backpropagation determines
whether to increase or decrease the weights applied to particular neurons.</p>
<p>The learning rate is a multiplier that controls the degree the which each backward pass
increase or decreases each weight. A larget learning rate will increase or decrease each
weight more than a small learning rate.</p>
<p>In calculus terms, backpropagation inplements calculus&rsquo; chain rule. That is,
backpropagation calculuates the partial derivative of the error with respect to each
parameter.</p>
<h2 id="model">model<a hidden class="anchor" aria-hidden="true" href="#model">#</a></h2>
<p>In general, any mathematical construct that processes input and returns output. Phrased
differently, a model is the set of parameters and structure needed for a system to make
predictions. In supervised machine learning, a model takes an example as input and
infers a prediction as output. Within supervised machine learning, models differ
somewhat. For example:</p>
<ul>
<li>A linear regression model consists of a set of weights and a bias.</li>
<li>A neural network model consists of:
<ul>
<li>A set of hidden layers, each containing one or more neurons.</li>
<li>The weights and bias associated with each neuron.</li>
</ul>
</li>
<li>A decision tree model consists of:
<ul>
<li>The shape of the tree; that is, the pattern in which the conditions and leaves are
connected.</li>
<li>The conditions and leaves.</li>
</ul>
</li>
</ul>
<p>You can save, restore, or make copies of a model.</p>
<p>Unsupervised machine learning also generates models, typically a function that can map
an input example to the most appropriate cluster.</p>
<h2 id="embeddings">embeddings<a hidden class="anchor" aria-hidden="true" href="#embeddings">#</a></h2>
<p>An embedding is a relatively low-dimensional space into which you can translate
high-dimensional vectors. Embeddings make it easier to do machine learning on large
inputs like sparse vectors representing words. Ideally, an embedding captures some of
the semantics of the input by placing semantically similar inputs close together in the
embedding space. An embedding can be learned and reused across models.</p>
<h2 id="automatic-differentiation">Automatic Differentiation<a hidden class="anchor" aria-hidden="true" href="#automatic-differentiation">#</a></h2>
<p>All modern deep learning frameworks take the differentiation work off of our plates by
offering <em>automatic differentiation</em> (often shortened to <em>autograd</em>). As we pass data
through each successive function, the framework build a <em>computational graph</em> that
tracks how each value depends on others. To calculate derivatives, automatic
differentiation works backwards through this graph applying the chain rule. The
computational algorithm for applying the <a href="/posts/2023-08-30_differential_calculus_recap/#chain-rule" >chain
rule</a> in this fashion is
called <em>backpropagation</em>.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://thomjiji.github.io/tags/machine-learning/">Machine Learning</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="https://thomjiji.github.io/blogs/2023/09/parse-quicktime/">
    <span class="title">« Prev</span>
    <br>
    <span>Parse QuickTime File Format</span>
  </a>
  <a class="next" href="https://thomjiji.github.io/blogs/2023/08/calculus-recap/">
    <span class="title">Next »</span>
    <br>
    <span>Calculus Recap</span>
  </a>
</nav>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2024 <a href="https://thomjiji.github.io/">thomjiji</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
