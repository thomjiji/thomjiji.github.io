[{"content":"对普通显示器校色的时候，很难不碰到 ICC profile 这个东西。我们都知道这个名词，显示器的 ICC 文件，或许模糊的对它有一些概念。但它究竟是什么？原理如何。\nICC profile 跟我们已经有很明确概念的 ACES，或者更广泛一些地讲：「现代的色彩管理流程」，是很相似的 idea。都有一个处于整个链路中间的非常大的色彩空间，大到足以容纳所有不同的输入、显示和输出设备的各种色域（sRGB、AdobeRGB、Rec.709 等等）1。这个色彩空间在 ICC 这个概念下叫作 PCS（Profile Connection Space）。ICC profile 通过定义设备源或目标色彩空间与 PCS 之间的映射来描述特定设备的色彩属性2。\nICC 本身并不进行任何校准，它们只包含显示器关于色彩成像能力的数据。这些数据用于帮助可以识别 ICC profile 的软件（我们叫它 ICC aware 的软件）通过 CMM（色彩管理模块）对图像进行调整，以尝试纠正显示器的色偏来进行校准。ICC profile 完成的实际上是对图像的调整，而不是对显示器的校正。不同的软件使用不同的 CMM 的话，即使都采用同一个 ICC，最终出来的结果也可能不一样。\nReference ICC Profile - IBM\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nICC profile - Wikipedia\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://thomjiji.github.io/posts/icc-profile/","summary":"对普通显示器校色的时候，很难不碰到 ICC profile 这个东西。我们都知道这个名词，显示器的 ICC 文件，或许模糊的对它有一些概念。但它究竟是什么？原理如何。\nICC profile 跟我们已经有很明确概念的 ACES，或者更广泛一些地讲：「现代的色彩管理流程」，是很相似的 idea。都有一个处于整个链路中间的非常大的色彩空间，大到足以容纳所有不同的输入、显示和输出设备的各种色域（sRGB、AdobeRGB、Rec.709 等等）1。这个色彩空间在 ICC 这个概念下叫作 PCS（Profile Connection Space）。ICC profile 通过定义设备源或目标色彩空间与 PCS 之间的映射来描述特定设备的色彩属性2。\nICC 本身并不进行任何校准，它们只包含显示器关于色彩成像能力的数据。这些数据用于帮助可以识别 ICC profile 的软件（我们叫它 ICC aware 的软件）通过 CMM（色彩管理模块）对图像进行调整，以尝试纠正显示器的色偏来进行校准。ICC profile 完成的实际上是对图像的调整，而不是对显示器的校正。不同的软件使用不同的 CMM 的话，即使都采用同一个 ICC，最终出来的结果也可能不一样。\nReference ICC Profile - IBM\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nICC profile - Wikipedia\u0026#160;\u0026#x21a9;\u0026#xfe0e;","title":"ICC Profile"},{"content":"之前我们知道，DisplayCAL 这种校色软件的工作原理：它会生成一个配置文件，在系统里加载，实际作用到显卡的输出信号上。更细节一点则是：\nDisplayCAL 生成的 ICC 配置文件中会包含一个叫作 VCGT（Video Card Gamma Table）的 tag，它实际是一个 1D LUT，包含对显示器的灰阶或白点的校正。然后操作系统需要把这个 VCGT Tag 加载到显卡输出信号上的有一个 Look Up Table 上，从而实现对显卡输出信号的校正。同时显卡的这个 Look Up Table 也是有精度限制的。\n具体在使用 DisplayCAL 的时候，右键桌面右下角 DisplayCAL 的图标，就会看到有一个 Reset video card gamma table 的东西。在系统加载了 DisplayCAL 生成的 profile 的情况下，这时点一下 Reset video card gamma table 会发现整个桌面的反差，或者说 Gamma、灰阶变了，它把对于显卡的校正给重置掉了，回到了最初的状态。\n再者就是我们还可以在 DisplayCAL 的 Tone curve 的设置中看到：如果不把 Tone curve 设为 “As measured” 的话，比如手动设为 Gamma 2.2。那 DisplayCAL 会做这么一件事情：在校准过程中，会通过一个 1D LUT 来校准（中和、补偿）显示器本身与这条纯粹的、Gamma 为 2.2 的指数曲线不相符的地方。如果设为 “As measured” 的话，则显示器的 grey scale 是怎么样就是怎么样，不做任何的校准和调整。\n总的来说：\nVCGT Tag 是一个 1D LUT，包含灰阶和白点的校准信息。是使用 DisplayCAL 这种软件校准时，实际起校准作用的环节。相对可感的。 VCGT 并不包含在 ICC 的标准中，因此有的软件可能把 VCGT（1D LUT）包含在了 ICC 配置文件当中，DisplayCAL 就是如此。有的软件可能包含在别的地方。 ","permalink":"https://thomjiji.github.io/posts/vcgt_tag/","summary":"之前我们知道，DisplayCAL 这种校色软件的工作原理：它会生成一个配置文件，在系统里加载，实际作用到显卡的输出信号上。更细节一点则是：\nDisplayCAL 生成的 ICC 配置文件中会包含一个叫作 VCGT（Video Card Gamma Table）的 tag，它实际是一个 1D LUT，包含对显示器的灰阶或白点的校正。然后操作系统需要把这个 VCGT Tag 加载到显卡输出信号上的有一个 Look Up Table 上，从而实现对显卡输出信号的校正。同时显卡的这个 Look Up Table 也是有精度限制的。\n具体在使用 DisplayCAL 的时候，右键桌面右下角 DisplayCAL 的图标，就会看到有一个 Reset video card gamma table 的东西。在系统加载了 DisplayCAL 生成的 profile 的情况下，这时点一下 Reset video card gamma table 会发现整个桌面的反差，或者说 Gamma、灰阶变了，它把对于显卡的校正给重置掉了，回到了最初的状态。\n再者就是我们还可以在 DisplayCAL 的 Tone curve 的设置中看到：如果不把 Tone curve 设为 “As measured” 的话，比如手动设为 Gamma 2.2。那 DisplayCAL 会做这么一件事情：在校准过程中，会通过一个 1D LUT 来校准（中和、补偿）显示器本身与这条纯粹的、Gamma 为 2.2 的指数曲线不相符的地方。如果设为 “As measured” 的话，则显示器的 grey scale 是怎么样就是怎么样，不做任何的校准和调整。","title":"VCGT Tag"},{"content":"做高端校色软件 ColourSpace 的 LightIllusion 有篇文章 What\u0026rsquo;s wrong with ICCs? 指出了 ICC profile 的一些问题。这非常关键，因为我们目前的校色流程就是基于 ICC profile 的。\n总的来说，ICC profile 能 work 的前提是软件本身支持它，软件是否是 ICC aware。通常来说 ICC aware 的软件有一个 CMM 色彩管理模块（Color Management Module）能够正确识别我们生成的 ICC profile，然后能够对图像做调整以达到「准确」的结果，实现校色的目的。先不说 ICC 这种方式本质上是对图像的调整，而不是对显示器本身的校正（后者是更好的方式，所谓硬件校准就是如此）。即使软件具有 CMM，准确度和性能还得看各个软件自身的优化。这就变成一件非常麻烦和复杂的事情。那些不是 ICC aware 的软件，看到的就做一个完全未经校准的画面。\n那对于 Adobe 全家桶来说，像 Ps、Lr 这种平面设计软件，它们是有 CMM 模块，叫作 ACE（Adobe Color Engine）。就是能够识别图像自带的 ICC profile，将其转换到 Ps 的工作色彩空间。那对于 Pr 来说，它也有被他们称为 DCM（Display Color Management）的东西，作为 Pr 内在的色彩管理方式，也是利用系统的 ICC profile 来进行工作的。\nDCM uses the ICC profile for your monitor to apply a colorimetric conversion from the sequence working color space (or media color space in the case of the source monitor) to the monitor color space. The profile is specified by the operating system. We generally recommended using the default profile that the system choses for your display. If your monitor has been professionally calibrated, use that profile. The default profile may have the name of your monitor or something generic like “Color LCD”. Using the specified display profile will ensure predictable colors across the system and in other apps like web browsers and email. DCM requires GPU Acceleration. GPU acceleration can be configured in Project Settings \u0026gt; General \u0026gt; Video Rendering and Playback. 1\nICC 主要还是平面设计领域的色彩管理方案，对于视频来说有很多局限性。虽然 ICC profile 是一种常见的色彩管理方式，但它并不是完美的，因为它只是对图像进行调整，而不是对显示器本身进行校正。使用上屏卡的一个最主要的原因就是绕过 ICC profile 乃至操作系统的整个色彩管理，更直接的获得一个干净的视频信号，而不去经过操作系统的色彩管理。而且对于监视器来说，一般需要是 SDI 接口，上屏卡也能满足这一点要求。\nReference New HDR Workflow in Premiere Pro - 2020 User Guide (PDF)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://thomjiji.github.io/posts/why-do-we-need-video-card/","summary":"做高端校色软件 ColourSpace 的 LightIllusion 有篇文章 What\u0026rsquo;s wrong with ICCs? 指出了 ICC profile 的一些问题。这非常关键，因为我们目前的校色流程就是基于 ICC profile 的。\n总的来说，ICC profile 能 work 的前提是软件本身支持它，软件是否是 ICC aware。通常来说 ICC aware 的软件有一个 CMM 色彩管理模块（Color Management Module）能够正确识别我们生成的 ICC profile，然后能够对图像做调整以达到「准确」的结果，实现校色的目的。先不说 ICC 这种方式本质上是对图像的调整，而不是对显示器本身的校正（后者是更好的方式，所谓硬件校准就是如此）。即使软件具有 CMM，准确度和性能还得看各个软件自身的优化。这就变成一件非常麻烦和复杂的事情。那些不是 ICC aware 的软件，看到的就做一个完全未经校准的画面。\n那对于 Adobe 全家桶来说，像 Ps、Lr 这种平面设计软件，它们是有 CMM 模块，叫作 ACE（Adobe Color Engine）。就是能够识别图像自带的 ICC profile，将其转换到 Ps 的工作色彩空间。那对于 Pr 来说，它也有被他们称为 DCM（Display Color Management）的东西，作为 Pr 内在的色彩管理方式，也是利用系统的 ICC profile 来进行工作的。\nDCM uses the ICC profile for your monitor to apply a colorimetric conversion from the sequence working color space (or media color space in the case of the source monitor) to the monitor color space.","title":"为什么要使用上屏卡"},{"content":"DisplayCAL 官网 User Guide 在对显示器校色之前，必须预热至少 30 分钟。这一点在我最近的校准过程中可以明确体会到，比如：在调整显示器自身的 RGB 输出时，当你把红绿蓝三个通道终于调到一条线上之后，这时亮度不达标了。调节显示器的亮度以达到目标值，比如 100 nits 之后，RGB 那三个值又不在一条线上了。一方面跟显示器的素质有关，不能保证在亮度增减的同时保持 RGB 三个值的输出一致。另一方面也跟显示器预热有关，没到 30 分钟状态还不稳定。\n显示器校准的基本概念：Calibration 和 Profiling/Characterization。在使用 DisplayCAL 进行校准的时候，第一步就是通过显示器自身的调节按钮，比如显示器的 RGB 三通道值的输出，来与事先定义好的目标值匹配。调节显示器的亮度按钮使其达到比如 100 尼特；在色温选项里使用用户自定义的方式来调节 RGB 输出，使其达到比如 6500K 的色温（CCT）。这一步我们粗略的称之为校准 Calibration，需要人手动去调的。而第二步是软件自动实现的过程，叫做 Profiling，就是它会在屏幕上生成一系列色块，测量这些色块的值，与标准值进行匹配，然后生成一个 Profile (e.g. ICC profile) 给我们最终加载到系统上。Profiling 实际上并不改变颜色，它描述的是该显示器对各种颜色的响应，通常存储在一个 ICC 配置文件中。\nCharacterization (or profiling) is recording the way a device reproduces or responds to color. Typically the result is stored in a device ICC profile. Such a profile does not in itself modify color in any way. What it does is allow a system such as a CMM (Color Management Module) or color aware application to modify color when combined with another device profile. Only by knowing the characteristics of two devices or colorspaces, can a way of transferring color from one device representation to another be achieved.1\n之前在用 i1 Display Pro 这个色度计搭配 DisplayCAL 软件来校色的时候，校出来的结果你很难相信它是准确的。很多时候都是偏红偏黄。这当然是由很多因素导致的，每个显示器的素质不同，甚至同一型号的两台显示器也会是不同的结果。显示器面板老化等等。但有一点是之前比较忽略的，就是这个色度计这个探头本身是不是准的。\n色度计（Colorimeter）也需要在硬件或软件上进行校准2，以便从不同类型的显示器上获得正确的测量结果。色度计这个东西，一般是针对某一类或者某一个的显示设备，然后就专门用于那一类或那一个显示器的校准了，一般不用于其他显示器校准。因为当初是只针对那一个显示器做了色度计自身的硬件校准。如果色度计在最初，比如出厂前，没有针对某一类显示器做硬件校准。那么就需要使用光谱仪（Spectrometer）对那个显示器进行测量，计算出一个结果作为一个校准文件给搭配色度计使用的软件加载，这就是对色度计进行所谓的软件的校准。光谱仪（Spectrometer）据我所知非常昂贵，也不知道什么地方能搞到。但 DisplayCAL 官网有一个数据库3，里面就有别人使用光谱仪针对 i1 Display Pro 和各种显示器、监视器的校准文件。我们直接拿到那个校准文件也能用。但毕竟是别人在他们自己的那个设备上测量的结果，跟我们手上的显示器可能还是有一定偏差（虽然是同一型号的显示器）。我们可以在 DisplayCAL 软件里很方便的加载这个校准文件。\n那么即便有了这个对与色度计自身进行校准的文件，我们使用 6500K 色温作为目标值校准出来的结果，你放一个纯白出来，比如开一个文件资源管理器，也很难说这就是一个纯白。当然白色这个概念，人眼对于白的感知就挺主观的，而且是可以适应它的。但是在正常办公室光照条件下，那个屏幕摆在那你一眼看过去就是感觉它偏黄，这能怎么办呢。使用 i1 Display Pro 对 MacBook Pro 的屏幕进行测量会发现，它的色温是 7000K 左右。我们都知道 Rec.709 也好 sRGB 也好，白点都是 D65，也就是 6500K。为什么苹果 MBP 的屏幕是 7000K 的色温呢。我在我自己的 MBP 14 吋上，使用不同的显示预设（BT.709-BT.1886、sRGB、XDR-1600nits）测量出来的色温也都是 7000K 上下。我不知道是不是因为其实大多数用户，更偏好一个理论上更偏冷的屏幕（7000K），而不是一个标准的但肉眼看上去比较暖、比较黄的屏幕（6500K）。\n总之使用 7000K 的色温作为目标值，加载针对不同显示器的 i1 Display Pro 的校准文件，校准出来的结果是比较符合预期的。另外两个 Dell 的主副屏显示器，校准之前，两个屏幕有很明显的色差。使用 DisplayCAL 校准的时候，以 7000K 色温为目标值，先在显示器的 RGB 设置调节上，把 RGB 输出调到一条线上，然后点继续。等自动化的 Profiling 过程结束后，我们对比校准前和校准后，可以得到一个不错的匹配。副屏在校准之前，暗部区域比主屏要偏蓝偏青，然后感觉整个屏幕的饱和度都要比主屏高。校准之后有所改善。\nBenQ SW 系列的硬件校色功能 BenQ 的 SW 系列相比于 PD 系列具有硬件校色功能，使用 BenQ 的软件 Palette Master Element4 搭配 X-rite 的 i1 Display Pro 色度计可以让校色结果直接储存和加载到显示器本身，使用显示器自身芯片进行色彩校正。而不是像软件校色那样，校色结果储存在电脑，作用在显卡，然后将信号给到显示器。据明基 BenQ 所说，这种硬件校色的实现相比软件校色更优5。一款显示器的好坏与否，除了它自身的素质之外，有方便的机制可以让我们对其进行定期的校色，也是很重要的衡量因素。因此 BenQ SW270C 和 SW271C 具有的硬件校色功能是一个加分项。\n安装 Palette Master Element 软件时，会要求用 USB Type-B 线把显示器和电脑连接，然后会自动安装 BenQ 的驱动。安装好之后的使用和校准都需要保持显示器和电脑的 USB 连接。校准的设置并不多，总的分为两块：校准和验证。校准菜单下可设置的选项也不多，白点（D65），RGB 三原色（我们选 sRGB），亮度（我们设置为 80 尼特），伽马（2.2），黑点（绝对零位）。然后点击下一步。BenQ SW270C 提供三个校准的槽位，我们可以选择将校准 LUT 加载在可选的「校准 1」里，然后就可以开始测量了。把 i1 Display Pro 的探头贴在显示器的正中央，让软件运行，进行校准。校准 LUT 会自动加载。最后是验证校准的结果，也是跑一遍色块，最后得到校准的结果。Delta E。GSJ-9 我这次的校准结果的平均 Delta E 是 0.45，最带 Delta E 是 0.76。光看这个结果，数字上是非常不错的。理论上 Delta E 小于 2，人眼就很难看出区别了。\nReference Calibration vs. Characterization - ArgyllCMS\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nA note about colorimeters, displays and DisplayCAL - DisplayCAL\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nColorimeter Corrections Database - DisplayCAL\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nBenQ Palette Master Element Software - BenQ\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nHardware vs. Software Calibration Updated 2021 - BenQ\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://thomjiji.github.io/posts/%E6%98%BE%E7%A4%BA%E5%99%A8%E6%A0%A1%E8%89%B2%E7%AC%94%E8%AE%B0/","summary":"DisplayCAL 官网 User Guide 在对显示器校色之前，必须预热至少 30 分钟。这一点在我最近的校准过程中可以明确体会到，比如：在调整显示器自身的 RGB 输出时，当你把红绿蓝三个通道终于调到一条线上之后，这时亮度不达标了。调节显示器的亮度以达到目标值，比如 100 nits 之后，RGB 那三个值又不在一条线上了。一方面跟显示器的素质有关，不能保证在亮度增减的同时保持 RGB 三个值的输出一致。另一方面也跟显示器预热有关，没到 30 分钟状态还不稳定。\n显示器校准的基本概念：Calibration 和 Profiling/Characterization。在使用 DisplayCAL 进行校准的时候，第一步就是通过显示器自身的调节按钮，比如显示器的 RGB 三通道值的输出，来与事先定义好的目标值匹配。调节显示器的亮度按钮使其达到比如 100 尼特；在色温选项里使用用户自定义的方式来调节 RGB 输出，使其达到比如 6500K 的色温（CCT）。这一步我们粗略的称之为校准 Calibration，需要人手动去调的。而第二步是软件自动实现的过程，叫做 Profiling，就是它会在屏幕上生成一系列色块，测量这些色块的值，与标准值进行匹配，然后生成一个 Profile (e.g. ICC profile) 给我们最终加载到系统上。Profiling 实际上并不改变颜色，它描述的是该显示器对各种颜色的响应，通常存储在一个 ICC 配置文件中。\nCharacterization (or profiling) is recording the way a device reproduces or responds to color. Typically the result is stored in a device ICC profile. Such a profile does not in itself modify color in any way.","title":"显示器校色笔记"},{"content":"Installation mp4muxer mp4demuxer Commands 将 MP4 的音视频分离（脱壳 Demux）： mp4demuxer --input-file input.mp4 --output-folder ~/Output 合并杜比视界 Profile 8.4 和杜比全景声双音轨： mp4muxer -i input.h265 --input-video-frame-rate 25 --hvc1flag 0 --dv-bl-compatible-id 4 -i Stereo.aac -i Atmos.ec3 -o DolbyVision_Atmos.mp4 合并 SDR 视频和杜比全景声双音轨: mp4muxer -i input.h264 --input-video-frame-rate 25 -i Stereo.aac -i Atmos.ec3 -o SDR\u0026amp;Atmos.mp4 ","permalink":"https://thomjiji.github.io/posts/dolbyvision_dolbyatmos/","summary":"Installation mp4muxer mp4demuxer Commands 将 MP4 的音视频分离（脱壳 Demux）： mp4demuxer --input-file input.mp4 --output-folder ~/Output 合并杜比视界 Profile 8.4 和杜比全景声双音轨： mp4muxer -i input.h265 --input-video-frame-rate 25 --hvc1flag 0 --dv-bl-compatible-id 4 -i Stereo.aac -i Atmos.ec3 -o DolbyVision_Atmos.mp4 合并 SDR 视频和杜比全景声双音轨: mp4muxer -i input.h264 --input-video-frame-rate 25 -i Stereo.aac -i Atmos.ec3 -o SDR\u0026amp;Atmos.mp4 ","title":"mp4muxer \u0026 mp4demuxer Basic Usage"},{"content":"操作步骤 把 ARRI Look Library 的文件包直接解压到这个路径，把里面的多个 cub 和 fllook 文件平摊在这个路径：/Library/Application Support/FilmLight/looks 把 ALF-2 v5 DRT Family 解压到这个路径，把里面的 cub 和 fltransform 平摊在这个路径：/Library/Application Support/FilmLight/etc/colourspaces 打开 Daylight，完成。 Reference ARRI Colour Workflow in Baselight ACES and Baselight ARRI Look Library and ALF-2 v5 DRT Family Download ","permalink":"https://thomjiji.github.io/posts/daylight-%E6%B7%BB%E5%8A%A0-arri-look-library-alf-2-v5-drt-family/","summary":"操作步骤 把 ARRI Look Library 的文件包直接解压到这个路径，把里面的多个 cub 和 fllook 文件平摊在这个路径：/Library/Application Support/FilmLight/looks 把 ALF-2 v5 DRT Family 解压到这个路径，把里面的 cub 和 fltransform 平摊在这个路径：/Library/Application Support/FilmLight/etc/colourspaces 打开 Daylight，完成。 Reference ARRI Colour Workflow in Baselight ACES and Baselight ARRI Look Library and ALF-2 v5 DRT Family Download ","title":"Daylight 添加 ARRI Look Library \u0026 ALF-2 v5 DRT Family"},{"content":"Third-Party Software Parted Magic SEDutil Official Software Samsung T7 SSD support Secure Erase via Samsung Magicion Software (only Windows) How to perform a secure erase using Magicion Software - Puget Systems ","permalink":"https://thomjiji.github.io/posts/sanitize-secure-erase-ssd-drive-software/","summary":"Third-Party Software Parted Magic SEDutil Official Software Samsung T7 SSD support Secure Erase via Samsung Magicion Software (only Windows) How to perform a secure erase using Magicion Software - Puget Systems ","title":"Sanitize/Secure Erase SSD Drive Software"},{"content":"Reference Blog: Discovering org roam\n一些随机的摘抄 A zettelkasten consists of many individual notes with ideas and other short pieces of information that are taken down as they occur or are acquired. The notes are numbered hierarchically, so that new notes may be inserted at the appropriate place, and contain metadata to allow the note-taker to associate notes with each other. For example, notes may contain tags that describe key aspects of the note, and they may reference other notes.\nZettelasten 笔记法，每一个新的 node 的文件名会添加上当前的时间戳？（numbered hierarchically）就像 Org Roam 一样。 每一个 node 会有 tag，就像我现在在 Obsidian 中尝试的一样。 He argues that in order to internalize something we need to re-elaborate it, curate it. We should also be able to let go some of these resources because they are not so precious. Let\u0026rsquo;s add action number 3 to the Zettelkasten method: improve and enrich your existing notes.\n有点道理，就像我的 Notion 一样，虽然自己做了很多分类，建了很多具有层级结构的 page。但是有一些 page 还是开始变得混乱起来，以至于我都不太想再去管理。你记的东西，为了能够内化它们，你需要去 curate 和 re-elaborate。\nPersonal wiki should not have a hierarchy notes should not have an hierarchy but structure should emerge spontaneously.\nWhen I want to add something to my wiki, I don\u0026rsquo;t want to worry about where to place the information (is it personal? is it work? is it machine learning or reinforcement learning?). I capture the blog post, notes about a book, youtube video, podcast and I add metadata. Then, smart software automates the process of creating a network of notes and visualizing it.\nI just finished converting my structured wiki into an unstructured one and it works much better. Let\u0026rsquo;s make an example. I had an org file called workflow.org, where I had collected information about different software I use. One heading for emacs, one heading for python, one heading for docker… One subheading for emacs is org-mode, with all the keybindings and useful functions.\nEach heading (and potentially subheading) has been turned into a node (take a look at Hugo\u0026rsquo;s Notes graph). It makes sense to have an emacs node, to which other nodes can refer to. For example org-mode is a node referring to it. The package org-roam I am about to describe is another node linking to both emacs and org.\n也是先建立一个「中心化」的 node，在这个 node 里去索引其他与之关联的 node，像他在这里说的：在 workflow.org 这个文档里，每个标题和子标题将会被转为一个单独的 node，拥有一个属于它们自己的 page。自然而然地，在标题和子标题们就和 workflow.org 链接上了。但是是以 workflow.org 为中心，如果我们在 Graph View 里来看的话。\nHierarchy is teared apart and structure emerges spontaneously. Whenever I want to add a new note about org, I will just add a new node and refer to the org node, I don\u0026rsquo;t need to care about which folder or file to write it in.\n","permalink":"https://thomjiji.github.io/posts/roam-zettelkasten/","summary":"Reference Blog: Discovering org roam\n一些随机的摘抄 A zettelkasten consists of many individual notes with ideas and other short pieces of information that are taken down as they occur or are acquired. The notes are numbered hierarchically, so that new notes may be inserted at the appropriate place, and contain metadata to allow the note-taker to associate notes with each other. For example, notes may contain tags that describe key aspects of the note, and they may reference other notes.","title":"Roam \u0026 Zettelkasten"},{"content":"Using echo touch file.md echo \u0026#34;hello\u0026#34; \u0026gt; file.md Using cat and standard redirect symbol \u0026gt; cat \u0026gt;\u0026gt; file.md This command creates an empty yet edited file as it prompts the user to create a text file and type in the file at the same time.\nIf you don\u0026rsquo;t want to edit the file, simply press CTRL+C and it will simply exit and create an empty file.\nIf you would like to add some text to the file, you can type in after this, like this:\ncat \u0026gt;\u0026gt; file.md This is some text in the file from command line. Reference https://www.geeksforgeeks.org/cat-command-in-linux-with-examples/\n","permalink":"https://thomjiji.github.io/posts/use-cat-command-to-add-text-to-file-quickly/","summary":"Using echo touch file.md echo \u0026#34;hello\u0026#34; \u0026gt; file.md Using cat and standard redirect symbol \u0026gt; cat \u0026gt;\u0026gt; file.md This command creates an empty yet edited file as it prompts the user to create a text file and type in the file at the same time.\nIf you don\u0026rsquo;t want to edit the file, simply press CTRL+C and it will simply exit and create an empty file.\nIf you would like to add some text to the file, you can type in after this, like this:","title":"Use cat command to add text to file quickly"},{"content":"参考链接 关于上传杜比视界到平台（Bilibili or Vimeo） How-To: Dolby Vision Encoding - Apple Compressor for Vimeo Dolby Vision for Vimeo FAQs Bilbili 技术发布的关于支持 HDR10 上传的文章 —— 2020 年 9 月 关于制作杜比全景声 Dolby Atmos Dolby Atmos Using Blackmagic Design DaVinci Resolve Studio 哔哩哔哩（B 站）杜比全景声/杜比音效稿件制作指南 —— 以白菜的名义 EP05 杜比全景声家庭版的交付和编码封装 —— 以白菜的名义 关于上传 HDR10 \u0026amp; HLG 到 Youtube Upload High Dynamic Range (HDR) videos Dolby Vision Basics Dolby Vision Metadata Levels What are Dolby Vision Profiles? What are the HEVC requirements for Dolby Vision encoding? HDR Monitor Consideration Common Dolby Vision Delivery Specifications iTunes Video and Audio Asset Guide 5.3.8 Some Topics What is Dolby Vision profile 8.4? Dolby Vision profiles describe the video codec and set of coding techniques used to encode a Dolby Vision video. Profile 8.4 is a Dolby Vision profile where the 10-bit HDR video essence is encoded using HEVC with a Hybrid Log Gamma (HLG) transfer function and is accompanied by dynamic Dolby Vision metadata. This is the format that is used when capturing HDR video on iPhone 12 or when exporting Dolby Vision video from Final Cut Pro or Compressor.\nProfile 8.4 is designed for direct distribution and playback on consumer devices (rather than, say, a mezzanine format optimized for OTT encoding). While there\u0026rsquo;s a growing range of consumer devices that support Dolby Vision playback, Profile 8.4 encodes are also built with a cross-compatible HLG base layer, so that if a device does not support Dolby Vision decoding, it can often decode just the HLG base layer, which will present a viewable picture, although decoding just the base layer—without any Dolby Vision metadata—does not take advantage of the sophisticated display mapping available in Dolby Vision displays.\nWhen Dolby Vision profile 8.4 files are played on Vimeo and on a Dolby Vision-capable device, the video player uses the Dolby Vision metadata to ensure that the content is mapped for the current display conditions.\nMaxFALL/MaxCLL Basic Background Info MaxFALL/MaxCLL is metadata required for HDR10 content.\nMaxFALL (Maximum Frame Average Light Level) indicates the maximum value of the frame average light level (in cd/m2 or nits) of the entire playback sequence. MaxFALL is calculated by averaging the decoded luminance values of all the pixels within a frame. MaxFALL is usually much lower than MaxCLL.\nMaxCLL (Maximum Content Light Level) indicates the maximum light level of any single pixel (in cd/m2 or nits) of the entire playback sequence. MaxCLL is usually measured off the final delivered content after mastering. If one uses the full light level of the HDR mastering display and adds a hard clip at its maximum value, MaxCLL would be equal to the peak luminance of the mastering monitor.\nMaxCLL/MaxFALL together forms static metadata as it uses the same values for the entire program, while Dolby Vision dynamic metadata changes on a shot by shot (or when required, frame by frame) basis.\nBoth HDR10 and Dolby Vision are based on the ST.2084 EOTF.\nDifferent consumer HDR displays have different peak luminance and contrast capabilities, and more than often these fall below the capabilities of the mastering monitors used in professional post production. Therefore in most cases, PQ encoded images will have to be scaled or mapped to match the capabilities of the target consumer display device. This scaling or mapping is controlled and managed by metadata.\nMaxFALL/MaxCLL Calculation MaxFALL/MaxCLL metadata is not required for a Dolby Vision deliverable, nevertheless, Dolby supports the effort to supply good and correct metadata to produce better end user entertainment experiences. MaxFALL/MaxCLL are not normally calculated as part of the Dolby Vision metadata creation process. They require a separate analysis that can be performed on systems like Colorfront Transkoder, MTI Cortex, etc.\nAlternatively, MaxFALL/MaxCLL metadata can be calculated using Dolby\u0026rsquo;s cm_analyze which is included in the Dolby Vision Professional Tools suite. Once these values are calculated, they can be added to an existing Dolby Vision XML as Level6 (L6) metadata so as to deliver both Dolby Vision as well as HDR10 metadata in a single metadata asset.\nHow do I create a Dolby Vision project in Blackmagic Design DaVinci Resolve? From an HDR sequence in Blackmagic Design Resolve, export to a mezzanine format (such as Apple ProRes 422 HQ) that supports PQ or HLG based HDR. Import this file into Apple Compressor and use a Dolby Vision 8.4 preset to transcode.\nDolby Atmos Master Formats: ADM BWF Source: Module 1.2 – Beyond Multichannel Audio\nThe Dolby Atmos Renderer records up to 128 inputs comprised of Bed and Object audio, OAMD as well as Binaural, Downmix, and Trim metadata, Input and Re-render configurations.\nThese are recorded to a Dolby Atmos Master File set (DAMF). This is the format native to the Dolby Atmos Renderer and is recorded as a three-file set comprised of:\natmos — An XML file containing information about the Dolby Atmos presentation and index information about the other files in the file set. The .atmos file includes the number of inputs used as Beds or Objects, frame rate, file start, first frame of action, the number of elements used in spatial coding, downmix, and trim metadata. atmos.metadata — An XML file containing dynamic positional and size OAMD for each Object, along with binaural metadata settings. atmos.audio — A Core Audio Format (CAF) file of up to 128 tracks of interleaved audio. The .atmos and .atmos.metadata files can be opened for inspection with a text editor. However, direct editing of these files is not recommended, as the file set can become corrupted.\nWhile a new master is always recorded as a DAMF, two other formats are used for distribution, for encoding, or further editing:\nADM BWF — The Audio Definition Model Broadcast Wav Format (ADM BWF) is an alternative Dolby Atmos master format. With ADM BWF (sometimes referred to as ADM BWAV), all other information included in the .atmos and .atmos.metadata files is included in a data chunk in the header of the wav file. The audio payload itself is up to 128 tracks of interleaved audio. ADM has several advantages: ADM BWF is a single file instead of three files in a folder, making it easy to interchange with other facilities. ADM BWF can be imported into DAWs. This allows all Bed and Object audio tracks to be recreated along with all the panning metadata. This allows for subsequent editing — language replacement, timing conformance, censorship edits, etc. — prior to remastering. ADM BWF can be encoded to Dolby True HD, Dolby Digital Plus JOC, and Dolby AC-4 IMS and is the primary deliverable to streaming operators and Blu-ray authoring. IMF.IAB – Immersive Audio Bitstream is a mezzanine format for IMF (interoperability mastering format). IAB is considered a mezzanine format rather than a master format, as OAMD is quantized. IAB.mxf is used by third-party IMF packaging tools to create a delivery container for both Dolby Atmos and video (including Dolby Vision). While the Dolby Atmos Renderer natively records in the .atmos format only, it can convert to and export ADM BWF and IAB.MXF. The entire file can be exported, or basic top/tail (specified range) edits can be performed.\nThe Dolby Atmos Renderer can also open ADM BWF and IAB.MXF files as master files for playback, QC, basic top/tail editing, conversion (between the two formats), and re-export. However, some restrictions apply with open ADM BWF and IAB.MXF. Punch-in and other metadata editing are not permitted with ADM BWF and IAB.MXF. Conversion to .atmos from ADM BWF and IAB.MXF is not permitted.\nThe Dolby Atmos Conversion Tool (DACT) is a companion application to the Dolby Atmos Renderer and is required to convert from ADM BWF and IAB.MXF to .atmos, perform format and frame-rate conversions, as well as perform complex editing operations on master files. The Dolby Atmos Conversion Tool is a free utility.\nWhat is HLS and DASH Source: Dolby Vision Encoding of Mezzanine Assets\nIn order to distribute content via OTT/VOD, all sources get encoded via a standard video encoder to compress and reduce the file size of the video content, followed by a packager that puts the encoded bitstream into streaming formats, like DASH or HLS.\nHLS – HTTP Live Streaming – a format developed by Apple splits a video file into small segments that are contained within a MPEG2 transport stream or MP4, hence the extension “.ts” or “.mp4”. HLS requires an H.264 (AVC) or H.265 (HEVC) codec and is currently the only format supported by iOS, iPadOS, tvOS and Apple’s Safari browser.\nDASH - Dynamic Adaptive Streaming over HTTP – also known as MPEG-DASH – splits a video file into small segments as well. Unlike HLS, DASH is codec agnostic. It supports H.264, H.265, VP9, and other codecs as well.\nBoth HLS and DASH use a separate manifest file that links to the segments (and/or other manifests). Such a manifest file is a simple text file that is understood by players supporting HLS and/or DASH.\nNotes 需要有这三个 metadata 才能被 Youtube 或 Bilibili 正确识别为 HDR10： Reference: HDR videos using PQ signaling should also contain information about the display it was mastered on (SMPTE ST 2086 mastering metadata). It should also have details about the brightness (CEA 861-3 MaxFALL and MaxCLL). If it\u0026rsquo;s missing, we use the values for the Sony BVM-X300 mastering display.\nMastering display luminance Maximum Content Light Level (MaxCLL) Maximum Frame-Average Light Level (MaxFALL) 杜比视界 Profile 8.4 B 站投稿标准 Source 1: 【全球首家】杜比视界用户投稿功能上线啦！—— 哔哩哔哩创作中心 Source 2: 【攻略】杜比视界UGC视频制作和分享操作指南 —— 杜比 Dolby\nBit Rate: 30000 kbps Resolution: 3840x2160 60FPS Bit Depth: 10bit Transfer Function: HLG Codec: HEVC (H.265) Dolby Vision Profile 8.4 Container: MP4, MOV, M4V 杜比全景声 B 站投稿标准 全景声音轨 音频编码格式 E-AC-3（Dolby Atmos） 音频声道数 6（5.1）或者 8（7.1） 音频采样率 48kHz 音频码率 320kbps 以上 其他 HDR10 要求的 static metadata 由 MaxFALL 和 MaxCLL 组成，杜比视界的 L1 metadata 只是计算出 min ava max 三个值，在达芬奇的 Dolby Vision 面板里进行。\nHDR10 和杜比视界都有元数据来控制影调的映射，在不同峰值亮度设备上的 Tone mapping。只是 HDR10 是所谓静态的元数据，而杜比视界是动态的。后者在 Tone mapping 的控制视界都有元数据来控制影调视界都有元数据来控制影调上更好。\n","permalink":"https://thomjiji.github.io/posts/dolby-vision-profile-8.4-dolby-atmos/","summary":"参考链接 关于上传杜比视界到平台（Bilibili or Vimeo） How-To: Dolby Vision Encoding - Apple Compressor for Vimeo Dolby Vision for Vimeo FAQs Bilbili 技术发布的关于支持 HDR10 上传的文章 —— 2020 年 9 月 关于制作杜比全景声 Dolby Atmos Dolby Atmos Using Blackmagic Design DaVinci Resolve Studio 哔哩哔哩（B 站）杜比全景声/杜比音效稿件制作指南 —— 以白菜的名义 EP05 杜比全景声家庭版的交付和编码封装 —— 以白菜的名义 关于上传 HDR10 \u0026amp; HLG 到 Youtube Upload High Dynamic Range (HDR) videos Dolby Vision Basics Dolby Vision Metadata Levels What are Dolby Vision Profiles? What are the HEVC requirements for Dolby Vision encoding?","title":"Dolby Vision Profile 8.4 \u0026 Dolby Atmos"},{"content":"Solution Add fish to $SHELL and set as default Add the shell to /etc/shells with: $ echo \u0026#34;/opt/homebrew/bin/fish\u0026#34; | sudo tee -a /etc/shells Change default shell with: chsh -s /opt/homebrew/bin/fish Modify $PATH with fish shell 在 iTerm2 当中使用 fish shell 作为默认 shell，需要把 $PATH 加入到 ~/.config/fish/fish_variables set -U fish_user_paths /usr/local/bin $fish_user_paths Type this command in terminal: fish_add_path /opt/homebrew/bin. It will add /opt/homebrew/bin to the ~/.config/fish/fish_variables. Other useful commands which $SHELL\necho $PATH\nHomebrew 下载的 Fish shell 的 path 在 /opt/homebrew/bin/fish 而不是像 fish documentation 说的那样在 /usr/local/bin/fish。\nReference why i can\u0026rsquo;t add fish to etc shells fish documentation: set default shell fish documentation: fish_add_path StackOverflow: Modify PATH with fish shell ","permalink":"https://thomjiji.github.io/posts/macos-add-fish-to-shell-and-set-fish-as-default-shell/","summary":"Solution Add fish to $SHELL and set as default Add the shell to /etc/shells with: $ echo \u0026#34;/opt/homebrew/bin/fish\u0026#34; | sudo tee -a /etc/shells Change default shell with: chsh -s /opt/homebrew/bin/fish Modify $PATH with fish shell 在 iTerm2 当中使用 fish shell 作为默认 shell，需要把 $PATH 加入到 ~/.config/fish/fish_variables set -U fish_user_paths /usr/local/bin $fish_user_paths Type this command in terminal: fish_add_path /opt/homebrew/bin. It will add /opt/homebrew/bin to the ~/.config/fish/fish_variables. Other useful commands which $SHELL\necho $PATH","title":"macOS add fish to $SHELL and set fish as default shell"},{"content":" Params Rate Control: CRF based VBR Quantizer: Nominal Quantizer parameter: 18 Quantizer parameter: 18 ","permalink":"https://thomjiji.github.io/posts/high-quality-h.264-render-in-baselight/","summary":" Params Rate Control: CRF based VBR Quantizer: Nominal Quantizer parameter: 18 Quantizer parameter: 18 ","title":"High Quality H.264 Render in Baselight"}]